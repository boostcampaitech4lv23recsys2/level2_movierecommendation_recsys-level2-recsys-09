{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already up-to-date: pandas in /opt/conda/lib/python3.8/site-packages (1.5.2)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied, skipping upgrade: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.3)\n","Requirement already satisfied, skipping upgrade: numpy>=1.20.3; python_version < \"3.10\" in /opt/conda/lib/python3.8/site-packages (from pandas) (1.23.5)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already up-to-date: numpy in /opt/conda/lib/python3.8/site-packages (1.23.5)\n"]}],"source":["!pip install --upgrade pandas\n","!pip install --upgrade numpy"]},{"cell_type":"markdown","metadata":{"id":"_B5CiikKdHcQ"},"source":["# DeepFM\n","\n","이번 실습에서는 DeepFM 모델을 이해하고 구현해보겠습니다.  \n","\n","DeepFM 모델은 Factorization machines와 neural network를 합친 모델로, Wide & Deep model과 유사하지만, feature engineering이 필요하지 않다는 특징을 가지고 있습니다.  \n","<br/>\n","사용자가 영화에 대해 Rating한 데이터, 영화의 장르 데이터를 이용하여 Train/Test data를 생성한 다음, Train data로 학습한 모델을 Test data에 대해 평가해봅니다.   \n","사용한 데이터는 Implicit feedback data로, 사용자가 시청한 영화(Positive instances)는 rating = 1로 기록됩니다. 따라서 시청하지 않은 영화에 대해 각 유저별로 Negative instances sampling을 진행합니다.   \n","<br/>\n","**구현에 앞서, DeepFM 논문을 꼭 읽어보시길 권장합니다.**\n","\n","* 참고  \n","    - DeepFM: A Factorization-Machine based Neural Network for CTR Prediction (https://arxiv.org/pdf/1703.04247.pdf)  \n","    - Wide & Deep Learning for Recommender Systems (https://arxiv.org/pdf/1606.07792.pdf)\n","    - Factorization Machines (https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5694074)\n","    - https://d2l.ai/chapter_recommender-systems/deepfm.html"]},{"cell_type":"markdown","metadata":{"id":"1rSLmkhCdHcR"},"source":["# Modules"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0-HAIZoIdHcS"},"outputs":[],"source":["import csv\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset"]},{"cell_type":"markdown","metadata":{"id":"dgCzGVEpdHcT"},"source":["# Data preprocessing\n","0. Dataset 다운로드  \n","<br/>\n","1. Rating df 생성  \n","rating 데이터(train_ratings.csv)를 불러와 [user, item, rating]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n","<br/>\n","2. Genre df 생성   \n","genre 정보가 담긴 데이터(genres.tsv)를 불러와 genre이름을 id로 변경하고, [item, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.    \n","<br/>\n","3. Negative instances 생성   \n","rating 데이터는 implicit feedback data(rating :0/1)로, positive instances로 구성되어 있습니다. 따라서 rating이 없는 item중 negative instances를 뽑아서 데이터에 추가하게 됩니다.   \n","<br/>\n","4. Join dfs   \n","rating df와 genre df를 join하여 [user, item, rating, genre]의 컬럼으로 구성된 데이터 프레임을 생성합니다.   \n","<br/>\n","5. zero-based index로 mapping   \n","Embedding을 위해서 user,item,genre를 zero-based index로 mapping합니다.\n","    - user : 0-31359\n","    - item : 0-6806\n","    - genre : 0-17  \n","<br/>\n","6. feature matrix X, label tensor y 생성   \n","[user, item, genre] 3개의 field로 구성된 feature matrix를 생성합니다.   \n","<br/>\n","7. data loader 생성"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"PuYBEIhYdHcU","outputId":"b5579ed8-6a0b-48e0-ebc2-fe4b71b1cc25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Raw rating df\n","           user   item  rating\n","0            11   4643     1.0\n","1            11    170     1.0\n","2            11    531     1.0\n","3            11    616     1.0\n","4            11   2140     1.0\n","...         ...    ...     ...\n","5154466  138493  44022     1.0\n","5154467  138493   4958     1.0\n","5154468  138493  68319     1.0\n","5154469  138493  40819     1.0\n","5154470  138493  27311     1.0\n","\n","[5154471 rows x 3 columns]\n","Raw genre df - changed to id\n","         item  genre\n","0         318     15\n","2        2571     16\n","5        2959     16\n","9         296      0\n","13        356      0\n","...       ...    ...\n","15925   73106      0\n","15926  109850     16\n","15929    8605     16\n","15931    3689      0\n","15932    8130      4\n","\n","[6807 rows x 2 columns]\n"]}],"source":["# 1. Rating df 생성\n","rating_data = \"../../data/train/train_ratings.csv\"\n","\n","raw_rating_df = pd.read_csv(rating_data)\n","raw_rating_df['rating'] = 1.0 # implicit feedback\n","raw_rating_df.drop(['time'],axis=1,inplace=True)\n","print(\"Raw rating df\")\n","print(raw_rating_df)\n","\n","users = set(raw_rating_df.loc[:, 'user'])\n","items = set(raw_rating_df.loc[:, 'item'])\n","\n","#2. Genre df 생성\n","genre_data = \"../../data/train/genres.tsv\"\n","\n","raw_genre_df = pd.read_csv(genre_data, sep='\\t')\n","raw_genre_df = raw_genre_df.drop_duplicates(subset=['item']) #item별 하나의 장르만 남도록 drop\n","#print(\"Raw genre df\")\n","#print(raw_genre_df)\n","\n","genre_dict = {genre:i for i, genre in enumerate(set(raw_genre_df['genre']))}\n","raw_genre_df['genre']  = raw_genre_df['genre'].map(lambda x : genre_dict[x]) #genre id로 변경\n","print(\"Raw genre df - changed to id\")\n","print(raw_genre_df)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HKJ2oJURdHcV","outputId":"0fe39bc3-70de-482f-bdbe-d738cb2d7381"},"outputs":[{"name":"stdout","output_type":"stream","text":["Create Nagetive instances\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 31360/31360 [06:16<00:00, 83.26it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Data\n","          user  item  rating  genre\n","0            0  2505     1.0     16\n","1            0  5497     1.0     15\n","2            0  1084     1.0      0\n","3            0  3201     1.0     16\n","4            0  1508     1.0     16\n","...        ...   ...     ...    ...\n","6722466  31359  1094     1.0     11\n","6722467  31359  6265     0.0     16\n","6722468  31359  3647     1.0     12\n","6722469  31359  1649     1.0      3\n","6722470  31359   822     1.0      0\n","\n","[6722471 rows x 4 columns]\n","# of data : 6722471\n","# of users : 31360\n","# of items : 6807\n","# of genres : 18\n"]}],"source":["# 3. Negative instance 생성\n","print(\"Create Nagetive instances\")\n","num_negative = 50\n","user_group_dfs = list(raw_rating_df.groupby('user')['item'])\n","first_row = True\n","user_neg_dfs = pd.DataFrame()\n","\n","for u, u_items in tqdm(user_group_dfs):\n","    u_items = set(u_items)\n","    i_user_neg_item = np.random.choice(list(items - u_items), num_negative, replace=False)\n","    \n","    i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'rating': [0]*num_negative})\n","    if first_row == True:\n","        user_neg_dfs = i_user_neg_df\n","        first_row = False\n","    else:\n","        user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n","\n","raw_rating_df = pd.concat([raw_rating_df, user_neg_dfs], axis = 0, sort=False)\n","\n","# 4. Join dfs\n","joined_rating_df = pd.merge(raw_rating_df, raw_genre_df, left_on='item', right_on='item', how='inner')\n","# print(\"Joined rating df\")\n","# print(joined_rating_df)\n","\n","# 5. user, item을 zero-based index로 mapping\n","users = list(set(joined_rating_df.loc[:,'user']))\n","users.sort()\n","items =  list(set((joined_rating_df.loc[:, 'item'])))\n","items.sort()\n","genres =  list(set((joined_rating_df.loc[:, 'genre'])))\n","genres.sort()\n","\n","if len(users)-1 != max(users):\n","    users_dict = {users[i]: i for i in range(len(users))}\n","    joined_rating_df['user']  = joined_rating_df['user'].map(lambda x : users_dict[x])\n","    users = list(set(joined_rating_df.loc[:,'user']))\n","    \n","if len(items)-1 != max(items):\n","    items_dict = {items[i]: i for i in range(len(items))}\n","    joined_rating_df['item']  = joined_rating_df['item'].map(lambda x : items_dict[x])\n","    items =  list(set((joined_rating_df.loc[:, 'item'])))\n","\n","joined_rating_df = joined_rating_df.sort_values(by=['user'])\n","joined_rating_df.reset_index(drop=True, inplace=True)\n","\n","data = joined_rating_df\n","print(\"Data\")\n","print(data)\n","\n","n_data = len(data)\n","n_user = len(users)\n","n_item = len(items)\n","n_genre = len(genres)\n","\n","print(\"# of data : {}\\n# of users : {}\\n# of items : {}\\n# of genres : {}\".format(n_data, n_user, n_item, n_genre))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"P3N75T9GdHcV"},"outputs":[],"source":["#6. feature matrix X, label tensor y 생성\n","user_col = torch.tensor(data.loc[:,'user'])\n","item_col = torch.tensor(data.loc[:,'item'])\n","genre_col = torch.tensor(data.loc[:,'genre'])\n","\n","offsets = [0, n_user, n_user+n_item]\n","for col, offset in zip([user_col, item_col, genre_col], offsets):\n","    col += offset\n","\n","X = torch.cat([user_col.unsqueeze(1), item_col.unsqueeze(1), genre_col.unsqueeze(1)], dim=1)\n","y = torch.tensor(list(data.loc[:,'rating']))\n","\n","\n","#7. data loader 생성\n","class RatingDataset(Dataset):\n","    def __init__(self, input_tensor, target_tensor):\n","        self.input_tensor = input_tensor.long()\n","        self.target_tensor = target_tensor.long()\n","\n","    def __getitem__(self, index):\n","        return self.input_tensor[index], self.target_tensor[index]\n","\n","    def __len__(self):\n","        return self.target_tensor.size(0)\n","\n","\n","dataset = RatingDataset(X, y)\n","train_ratio = 0.9\n","\n","train_size = int(train_ratio * len(data))\n","test_size = len(data) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"rgDhK2Q6dHcW"},"source":["   # Model architecture (DeepFM)\n","   DeepFM 모델은 1) FM component와  2) Deep component가 병렬적으로 결합되어 있습니다. 구조는 다음과 같습니다.\n","<img src='https://drive.google.com/uc?id=1vwcxUJQTIsg5QH9CuH5PcUEfExhToUHR'>  \n","각 구조는 다음과 같습니다.  \n","   **1. FM component**  \n","       FM component는 우리가 아는 2-way Factorization machines(degree=2)입니다. FM은 variables 간의 interaction을 다음과 같이 모델링 합니다.   \n","     **<center> equation (1) </center>**\n","   $$\\hat{y}(x):=w_0 + \\sum_{i=1}^{n}w_ix_i + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j$$   \n","   이때, 세번째 interaction term을 전개하여 다음과 같이 쓸 수 있습니다.(논문 참고)  \n","   구현 코드는 전개된 식을 바탕으로 합니다.   \n","     **<center> equation (2)> </center>**\n","   $$\\sum_{i=1}^{n}\\sum_{j=i+1}^{n}<\\mathbf{v}_i,\\mathbf{v}_j>x_ix_j = \\frac{1}{2}\\sum_{f=1}^{k}((\\sum_{i=1}^{n}v_{i,f}x_i)^2-\\sum_{i=1}^{n}v_{i,f}^2x_i^2)$$   \n","           \n","   **2. Deep component**  \n","       Deep component는 MLP Layers로 구성되어 있습니다.   \n","       구현 코드는 Input dimension이 30-20-10인 3 layer MLP 구조입니다.\n","  \n","   "]},{"cell_type":"markdown","metadata":{"id":"WxcLoGw2dHcW"},"source":["# DeepFM"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"SytZGp2_dHcW"},"outputs":[],"source":["class DeepFM(nn.Module):\n","    def __init__(self, input_dims, embedding_dim, mlp_dims, drop_rate=0.1):\n","        super(DeepFM, self).__init__()\n","        total_input_dim = int(sum(input_dims)) # n_user + n_movie + n_genre\n","\n","        # Fm component의 constant bias term과 1차 bias term\n","        self.bias = nn.Parameter(torch.zeros((1,)))\n","        self.fc = nn.Embedding(total_input_dim, 1)\n","        \n","        self.embedding = nn.Embedding(total_input_dim, embedding_dim) \n","        self.embedding_dim = len(input_dims) * embedding_dim\n","\n","        mlp_layers = []\n","        for i, dim in enumerate(mlp_dims):\n","            if i==0:\n","                mlp_layers.append(nn.Linear(self.embedding_dim, dim))\n","            else:\n","                mlp_layers.append(nn.Linear(mlp_dims[i-1], dim)) #TODO 1 : linear layer를 넣어주세요.\n","            mlp_layers.append(nn.ReLU(True))\n","            mlp_layers.append(nn.Dropout(drop_rate))\n","        mlp_layers.append(nn.Linear(mlp_dims[-1], 1))\n","        self.mlp_layers = nn.Sequential(*mlp_layers)\n","\n","    def fm(self, x):\n","        # x : (batch_size, total_num_input)\n","        embed_x = self.embedding(x)\n","\n","        fm_y = self.bias + torch.sum(self.fc(x), dim=1)\n","        square_of_sum = torch.sum(embed_x, dim=1) ** 2         #TODO 2 : torch.sum을 이용하여 square_of_sum을 작성해주세요(hint : equation (2))\n","        sum_of_square = torch.sum(embed_x ** 2, dim=1)         #TODO 3 : torch.sum을 이용하여 sum_of_square을 작성해주세요(hint : equation (2))\n","        fm_y += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n","        return fm_y\n","    \n","    def mlp(self, x):\n","        embed_x = self.embedding(x)\n","        \n","        inputs = embed_x.view(-1, self.embedding_dim)\n","        mlp_y = self.mlp_layers(inputs)\n","        return mlp_y\n","\n","    def forward(self, x):\n","        embed_x = self.embedding(x)\n","        #fm component\n","        fm_y = self.fm(x).squeeze(1)\n","        \n","        #deep component\n","        mlp_y = self.mlp(x).squeeze(1)\n","        \n","        y = torch.sigmoid(fm_y + mlp_y)\n","        return y\n"]},{"cell_type":"markdown","metadata":{"id":"KR-AgXXpdHcX"},"source":["# Training"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"1aEtDR5EdHcX","outputId":"ab74a388-e2e4-48a7-91da-364a638c0d31"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [14:33<00:00, 87.36s/it]\n"]}],"source":["device = torch.device('cuda')\n","input_dims = [n_user, n_item, n_genre]\n","embedding_dim = 10\n","model = DeepFM(input_dims, embedding_dim, mlp_dims=[30, 20, 10]).to(device)\n","bce_loss = nn.BCELoss() # Binary Cross Entropy loss\n","lr, num_epochs = 0.01, 10\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","for e in tqdm(range(num_epochs)) :\n","    for x, y in train_loader:\n","        x, y = x.to(device), y.to(device)\n","        model.train()\n","        optimizer.zero_grad()\n","        output = model(x)\n","        loss = bce_loss(output, y.float())\n","        loss.backward()\n","        optimizer.step()\n","        "]},{"cell_type":"markdown","metadata":{"id":"o1ubPYdudHcX"},"source":["# Evaluation\n","평가는 모델이 postive instance에 대해 0.5이상, negative instance에 대해 0.5미만의 값을 예측한 Accuracy를 측정하여 진행됩니다."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"y6CA01h9dHcX","outputId":"0c87143f-8c63-47cf-a650-532f69cb14e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final Acc : 90.40%\n"]}],"source":["correct_result_sum = 0\n","for x, y in test_loader:\n","    x, y = x.to(device), y.to(device)\n","    model.eval()\n","    output = model(x)\n","    result = torch.round(output)\n","    correct_result_sum += (result == y).sum().float()\n","\n","acc = correct_result_sum/len(test_dataset)*100\n","print(\"Final Acc : {:.2f}%\".format(acc.item()))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 31360/31360 [03:24<00:00, 153.01it/s]\n"]}],"source":["# 모든 유저-아이템을 인풋으로 넣어서 결과 생성 후 랭킹 (31360 x 6807)\n","u_list = []\n","i_list = []\n","ritems_dict = {v:k for k,v in items_dict.items()}\n","for u, u_items in tqdm(user_group_dfs):\n","\n","    # 인코딩하기 전에 유저id 저장\n","    u_list.append([u]*10)\n","\n","    # user_group_dfs은 인코딩 이전 값이므로 사용하기 위해 인코딩 진행\n","    u = users_dict[u]\n","    u_items = set(u_items.map(lambda x : items_dict[x]))    # 인덱스로 활용 가능!\n","\n","    # user, item, genre 데이터를 인코딩하여 학습한 모델에 맞는 값으로 변환\n","    i_user_col = torch.tensor([u] * n_item)\n","    i_item_col = torch.tensor(raw_genre_df['item'].map(lambda x : items_dict[x]).values)\n","    i_genre_col = torch.tensor(raw_genre_df['genre'].values)\n","    for col, offset in zip([i_user_col, i_item_col, i_genre_col], offsets):\n","        col += offset\n","    \n","    x = torch.cat([i_user_col.unsqueeze(1), i_item_col.unsqueeze(1), i_genre_col.unsqueeze(1)], dim=1)\n","    x = x.to(device)\n","\n","    model.eval()\n","    output_batch = model(x)\n","    output_batch = output_batch.cpu().detach().numpy()\n","\n","    output_batch[list(u_items)] = -np.inf   # 이미 본 아이템 제외\n","    result_batch = np.argsort(output_batch)[-10:][::-1] # 역방향 -> 정방향으로 수정\n","    i_list.append(list(map(lambda x : ritems_dict[x], result_batch)))  # 아이템 디코딩, ndarray는 map()이 안돼서 다른 방법 찾음"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["u_list = np.concatenate(u_list)\n","i_list = np.concatenate(i_list)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["submit_df = pd.DataFrame(data={'user': u_list, 'item': i_list}, columns=['user', 'item'])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["if not os.path.exists(\"./submit/\"):\n","    os.makedirs(\"./submit/\")\n","submit_df.to_csv(\"./submit/\"+\"deepfm_submission.csv\", index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"j8J_TsC1Jj6E"},"source":["### **콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n","\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1AEKlEI3Vy2yubjb6XnZDCqGUquGVdPHK","timestamp":1670817510939}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
