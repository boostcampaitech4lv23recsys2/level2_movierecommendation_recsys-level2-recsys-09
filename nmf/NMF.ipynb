{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import os, random\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 \n",
    "class cfg: \n",
    "    gpu_idx = 0\n",
    "    device = torch.device(\"cuda:{}\".format(gpu_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "    top_k = 10\n",
    "    seed = 42\n",
    "    neg_ratio = 80\n",
    "    test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정 \n",
    "def seed_everything(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "seed_everything(cfg.seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "DATA_PATH = '../../input/data/train/'\n",
    "saved_path = '../saved'\n",
    "data = pd.read_csv(os.path.join(DATA_PATH, 'train_ratings.csv'), header=0)\n",
    "genre_data = pd.read_csv(os.path.join(DATA_PATH, 'genres.tsv'), sep='\\t')\n",
    "# rating 설정\n",
    "# data['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(DATA_PATH, 'train_ratings.csv'), header = 0)['item'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "\n",
    "    return count\n",
    "\n",
    "# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상) \n",
    "# 데이터만을 추출할 때 사용하는 함수입니다.\n",
    "# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'item')\n",
    "        tp = tp[tp['item'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'user')\n",
    "        tp = tp[tp['user'].isin(usercount.index[usercount >= min_uc])]\n",
    "\n",
    "    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n",
    "    return tp, usercount, itemcount\n",
    "\n",
    "#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n",
    "#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n",
    "#확인하기 위함입니다.\n",
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('user')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(cfg.seed)\n",
    "    \n",
    "    for _, group in data_grouped_by_user:\n",
    "        n_items_u = len(group)\n",
    "        \n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        \n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "    \n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "\n",
    "    return data_tr, data_te\n",
    "\n",
    "def numerize(tp, profile2id, show2id):\n",
    "    uid = tp['user'].apply(lambda x: profile2id[x])\n",
    "    sid = tp['item'].apply(lambda x: show2id[x])\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\n",
      "    user  item        time\n",
      "0    11  4643  1230782529\n",
      "1    11   170  1230782534\n",
      "2    11   531  1230782539\n",
      "3    11   616  1230782542\n",
      "4    11  2140  1230782563\n",
      "유저별 리뷰수\n",
      " user\n",
      "11    376\n",
      "14    180\n",
      "18     77\n",
      "25     91\n",
      "31    154\n",
      "dtype: int64\n",
      "아이템별 리뷰수\n",
      " item\n",
      "1    12217\n",
      "2     3364\n",
      "3      734\n",
      "4       43\n",
      "5      590\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(data, min_uc=5, min_sc=0)\n",
    "#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n",
    "print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data.head())\n",
    "\n",
    "print(\"유저별 리뷰수\\n\",user_activity.head())\n",
    "print(\"아이템별 리뷰수\\n\",item_popularity.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEFORE) unique_uid: Int64Index([11, 14, 18, 25, 31], dtype='int64', name='user')\n",
      "(AFTER) unique_uid: Int64Index([81259, 11986, 67552, 127325, 115853], dtype='int64', name='user')\n",
      "훈련 데이터에 사용될 사용자 수: 28224\n",
      "검증 데이터에 사용될 사용자 수: 3136\n"
     ]
    }
   ],
   "source": [
    "# Shuffle User Indices\n",
    "unique_uid = user_activity.index\n",
    "print(\"(BEFORE) unique_uid:\",unique_uid[:5])\n",
    "np.random.seed(cfg.seed)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "print(\"(AFTER) unique_uid:\",unique_uid[:5])\n",
    "\n",
    "n_users = unique_uid.size #31360\n",
    "n_heldout_users = int(0.1 * n_users)\n",
    "\n",
    "\n",
    "# Split Train/Validation/Test User Indices\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "\n",
    "#주의: 데이터의 수가 아닌 사용자의 수입니다!\n",
    "print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n",
    "print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "##훈련 데이터에 해당하는 아이템들\n",
    "#Train에는 전체 데이터를 사용합니다.\n",
    "train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n",
    "\n",
    "##아이템 ID\n",
    "unique_sid = pd.unique(train_plays['item'])\n",
    "\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "\n",
    "pro_dir = os.path.join(DATA_PATH, 'pro_sg')\n",
    "\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)\n",
    "\n",
    "\n",
    "vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n",
    "\n",
    "train_data = numerize(train_plays, profile2id, show2id)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
    "\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "\n",
    "vad_data = numerize(vad_plays, profile2id, show2id)\n",
    "vad_data.to_csv(os.path.join(pro_dir, 'validation.csv'), index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13266</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13266</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>4927</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>4927</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>4927</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>4927</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>4927</td>\n",
       "      <td>2236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4633543 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid   sid\n",
       "0        13266     0\n",
       "1        13266     1\n",
       "2        13266     2\n",
       "3        13266     3\n",
       "4        13266     4\n",
       "...        ...   ...\n",
       "5154466   4927   423\n",
       "5154467   4927  1458\n",
       "5154468   4927   331\n",
       "5154469   4927   733\n",
       "5154470   4927  2236\n",
       "\n",
       "[4633543 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cfg 설정\n",
    "- numerize -> vaild, test\n",
    "- item 크기 안맞는 형상 -> 수정 필요 (by unique_sid text 변형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train_users = len(unique_uid) + 1\n",
    "cfg.train_items = train_data['sid'].max()+1\n",
    "cfg.valid_users = vad_data['uid'].nunique()\n",
    "cfg.valid_items = vad_data['sid'].max() + 1\n",
    "cfg.test_users = test_data['uid'].nunique()\n",
    "cfg.test_items = test_data['sid'].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31361"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_uid) + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Input -> Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99987960e4e4900bd665af2c641ad45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4116739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data 형태: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix 형태로 변환 \n",
    "train_data = train_data.to_numpy()\n",
    "matrix = sparse.lil_matrix((cfg.train_users, cfg.train_items))\n",
    "for (p, i) in tqdm(train_data):\n",
    "    matrix[p, i] = 1\n",
    "    \n",
    "train_data = sparse.csr_matrix(matrix)\n",
    "train_data = train_data.toarray()\n",
    "print(\"train_data 형태: \\n\", train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "genre_data = pd.read_csv(os.path.join(DATA_PATH, 'genres.tsv'), sep='\\t')\n",
    "genre_data['genre'] = le.fit_transform(genre_data['genre'])\n",
    "genre_data['item'] = le.fit_transform(genre_data['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item 749의 genre 정보 : 7\n"
     ]
    }
   ],
   "source": [
    "# 아이템 특징 정보 추출 \n",
    "genre_data = genre_data.set_index('item')\n",
    "# 범주형 데이터를 수치형 데이터로 변경 \n",
    "genre_data['genre'] = le.fit_transform(genre_data['genre'])\n",
    "item_features = genre_data[['genre']].to_dict()\n",
    "print(\"item 749의 genre 정보 :\", item_features['genre'][749])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    \"\"\"Neural Matrix Factorization Model\n",
    "        참고 문헌 : https://arxiv.org/abs/1708.05031\n",
    "\n",
    "    예시 :\n",
    "        model = NeuMF(cfg) \n",
    "        output = model.forward(user_ids, item_ids, [feat0, feat1]) \n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            cfg : config 파일로 네트워크 생성에 필요한 정보들을 담고 있음 \n",
    "        \"\"\"\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.n_users = cfg.train_users\n",
    "        self.n_items = cfg.train_items\n",
    "        self.emb_dim = cfg.emb_dim\n",
    "        self.layer_dim = cfg.layer_dim\n",
    "        # self.n_continuous_feats = cfg.n_continuous_feats\n",
    "        self.n_genres = cfg.n_genres\n",
    "        self.dropout = cfg.dropout\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Neural Matrix Factorization Model 생성\n",
    "            구현된 모습은 위의 그림을 참고 \n",
    "        \"\"\"\n",
    "        self.user_embedding_mf = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)\n",
    "        self.item_embedding_mf = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "        \n",
    "        self.user_embedding_mlp = nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.emb_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.emb_dim)\n",
    "                \n",
    "        self.genre_embeddig = nn.Embedding(num_embeddings=self.n_genres, embedding_dim=self.n_genres//2)\n",
    "        \n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Linear(2*self.emb_dim + self.n_genres//2 , self.layer_dim),  # + self.n_continuous_feats\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=self.dropout), \n",
    "            nn.Linear(self.layer_dim, self.layer_dim//2), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(p=self.dropout)\n",
    "        )\n",
    "        self.affine_output = nn.Linear(self.layer_dim//2 + self.emb_dim, 1)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            normal_(module.weight.data, mean=0.0, std=0.01)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            normal_(module.weight.data, 0, 0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices, feats):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            user_indices : 유저의 인덱스 정보 \n",
    "                ex) tensor([ 3100,  3100,  ..., 14195, 14195])\n",
    "            item_indices : 아이템의 인덱스 정보\n",
    "                ex) tensor([   50,    65,   ..., 14960, 11527])\n",
    "            feats : 특징 정보 \n",
    "        Returns: \n",
    "            output : 유저-아이템 쌍에 대한 추천 결과 \n",
    "                ex) tensor([  9.4966,  22.0261, ..., -19.3535, -23.0212])\n",
    "        \"\"\"\n",
    "        user_embedding_mf = self.user_embedding_mf(user_indices)\n",
    "        item_embedding_mf = self.item_embedding_mf(item_indices)\n",
    "        mf_output = torch.mul(user_embedding_mf, item_embedding_mf)\n",
    "        \n",
    "        user_embedding_mlp = self.user_embedding_mlp(user_indices)\n",
    "        item_embedding_mlp = self.item_embedding_mlp(item_indices)\n",
    "        genre_embedding_mlp = self.genre_embeddig(feats[0])\n",
    "        input_feature = torch.cat((user_embedding_mlp, item_embedding_mlp, genre_embedding_mlp), -1) # , feats[0].unsqueeze(1)\n",
    "        mlp_output = self.mlp_layers(input_feature)\n",
    "        \n",
    "        output = torch.cat([mlp_output, mf_output], dim=-1)\n",
    "        output = self.affine_output(output).squeeze(-1)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 및 추론 코드 구현\n",
    "- 학습 : Negative sampling을 활용하여 Binary Classification 진행\n",
    "    - history 에 있는 album_id는 positive label로 그렇지 않은 album_id는 nagative label로 활용\n",
    "    - 단, 이때 모든 album_id를 negative label로 활용하는 것이 아닌 일부만 사용 (neg_ratio 값에 따라서 개수 조정)\n",
    "- 추론 : 일부 데이터에 대해 recall, ndcg, coverage 성능 확인"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UIdataset & Batchdataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_UIdataset(train, neg_ratio):\n",
    "    \"\"\" 유저별 학습에 필요한 딕셔너리 데이터 생성 \n",
    "    Args:\n",
    "        train : 유저-아이템의 상호작용을 담은 행렬 \n",
    "            ex) \n",
    "                array([[0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        ...,\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.],\n",
    "                        [0., 0., 0., ..., 0., 0., 0.]])\n",
    "        neg_ratio : negative sampling 활용할 비율 \n",
    "            ex) 3 (positive label 1개당 negative label 3개)\n",
    "    Returns: \n",
    "        UIdataset : 유저별 학습에 필요한 정보를 담은 딕셔너리 \n",
    "            ex) {'사용자 ID': [[positive 샘플, negative 샘플], ... , [1, 1, 1, ..., 0, 0]]}\n",
    "                >>> UIdataset[3]\n",
    "                    [array([   16,    17,    18, ...,  9586, 18991,  9442]),\n",
    "                    array([5, 5, 5, ..., 5, 5, 5]),\n",
    "                    array([4, 4, 4, ..., 5, 1, 1]),\n",
    "                    array([1., 1., 1., ..., 0., 0., 0.])]\n",
    "    \"\"\"\n",
    "    UIdataset = {}\n",
    "    for user_id, items_by_user in enumerate(train):\n",
    "        UIdataset[user_id] = []\n",
    "        # positive 샘플 계산 \n",
    "        pos_item_ids = np.where(items_by_user > 0.5)[0]\n",
    "        num_pos_samples = len(pos_item_ids)\n",
    "\n",
    "        # negative 샘플 계산 (random negative sampling) \n",
    "        num_neg_samples = neg_ratio * num_pos_samples\n",
    "        neg_items = np.where(items_by_user < 0.5)[0]\n",
    "        neg_item_ids = np.random.choice(neg_items, min(num_neg_samples, len(neg_items)), replace=False)\n",
    "        UIdataset[user_id].append(np.concatenate([pos_item_ids, neg_item_ids]))\n",
    "        \n",
    "        # feature 추출 \n",
    "        # features = []\n",
    "        # for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "        #     features.append(user_features['age'][user_id])\n",
    "        # UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        features = []\n",
    "        for item_id in np.concatenate([pos_item_ids, neg_item_ids]): \n",
    "            features.append(item_features['genre'][item_id])\n",
    "        UIdataset[user_id].append(np.array(features))\n",
    "        \n",
    "        # label 저장  \n",
    "        pos_labels = np.ones(len(pos_item_ids))\n",
    "        neg_labels = np.zeros(len(neg_item_ids))\n",
    "        UIdataset[user_id].append(np.concatenate([pos_labels, neg_labels]))\n",
    "\n",
    "    return UIdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIdataset = make_UIdataset(train_data, neg_ratio=cfg.neg_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batchdata(user_indices, batch_idx, batch_size):\n",
    "    \"\"\" 배치 데이터로 변환 \n",
    "    Args:\n",
    "        user_indices : 전체 유저의 인덱스 정보 \n",
    "            ex) array([ 3100,  1800, 30098, ...,  2177, 11749, 20962])\n",
    "        batch_idx : 배치 인덱스 (몇번째 배치인지)\n",
    "            ex) 0 \n",
    "        batch_size : 배치 크기 \n",
    "            ex) 256 \n",
    "    Returns \n",
    "        batch_user_ids : 배치내의 유저 인덱스 정보 \n",
    "            ex) [22194, 22194, 22194, 22194, 22194, ...]\n",
    "        batch_item_ids : 배치내의 아이템 인덱스 정보 \n",
    "            ex) [36, 407, 612, 801, 1404, ...]\n",
    "        batch_feat0 : 배치내의 유저-아이템 인덱스 정보에 해당하는 feature0 정보 \n",
    "            ex) [6, 6, 6, 6, 6, ...]\n",
    "        batch_feat1 : 배치내의 유저-아이템 인덱스 정보에 해당하는 feature1 정보 \n",
    "            ex) [4,  4,  4, 23,  4, ...]\n",
    "        batch_labels : 배치내의 유저-아이템 인덱스 정보에 해당하는 label 정보 \n",
    "            ex) [1.0, 1.0, 1.0, 1.0, 1.0, ...]\n",
    "    \"\"\"\n",
    "    batch_user_indices = user_indices[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "    batch_user_ids = []\n",
    "    batch_item_ids = []\n",
    "    batch_feat0 = []\n",
    "    # batch_feat1 = []\n",
    "    batch_labels = []\n",
    "    for user_id in batch_user_indices:\n",
    "        item_ids = UIdataset[user_id][0]\n",
    "        feat0 = UIdataset[user_id][1]\n",
    "        # feat1 = UIdataset[user_id][2]\n",
    "        labels = UIdataset[user_id][2]\n",
    "        user_ids = np.full(len(item_ids), user_id)\n",
    "        batch_user_ids.extend(user_ids.tolist())\n",
    "        batch_item_ids.extend(item_ids.tolist())\n",
    "        batch_feat0.extend(feat0.tolist())\n",
    "        # batch_feat1.extend(feat1.tolist())\n",
    "        batch_labels.extend(labels.tolist())\n",
    "    return batch_user_ids, batch_item_ids, batch_feat0,  batch_labels # batch_feat1,\n",
    "\n",
    "def update_avg(curr_avg, val, idx):\n",
    "    \"\"\" 현재 epoch 까지의 평균 값을 계산 \n",
    "    \"\"\"\n",
    "    return (curr_avg * idx + val) / (idx + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 및 검증 코드 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(cfg, model, optimizer, criterion): \n",
    "    model.train()\n",
    "    curr_loss_avg = 0.0\n",
    "\n",
    "    user_indices = np.arange(cfg.train_users)\n",
    "    np.random.RandomState(cfg.epoch).shuffle(user_indices)\n",
    "    batch_num = int(len(user_indices) / cfg.batch_size) + 1\n",
    "    bar = tqdm(range(batch_num), leave=False)\n",
    "    \n",
    "    for step, batch_idx in enumerate(bar):\n",
    "        user_ids, item_ids, feat0,  labels = make_batchdata(user_indices, batch_idx, cfg.batch_size) # feat1\n",
    "        # 배치 사용자 단위로 학습\n",
    "        user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "        item_ids = torch.LongTensor(item_ids).to(cfg.device)\n",
    "        feat0 = torch.LongTensor(feat0).to(cfg.device)\n",
    "        # feat1 = torch.LongTensor(feat1).to(cfg.device)\n",
    "        labels = torch.FloatTensor(labels).to(cfg.device)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # grad 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델 forward\n",
    "        output = model.forward(user_ids, item_ids, [feat0]) # , feat1\n",
    "        output = output.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 최적화\n",
    "        optimizer.step()    \n",
    "        if torch.isnan(loss):\n",
    "            print('Loss NAN. Train finish.')\n",
    "            break\n",
    "        curr_loss_avg = update_avg(curr_loss_avg, loss, step)\n",
    "        \n",
    "        msg = f\"epoch: {cfg.epoch}, \"\n",
    "        msg += f\"loss: {curr_loss_avg.item():.5f}, \"\n",
    "        msg += f\"lr: {optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        bar.set_description(msg)\n",
    "    rets = {'losses': np.around(curr_loss_avg.item(), 5)}\n",
    "    return rets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallk(actual, predicted, k = 25):\n",
    "    \"\"\" label과 prediction 사이의 recall 평가 함수 \n",
    "    Args:\n",
    "        actual : 실제로 본 상품 리스트\n",
    "        pred : 예측한 상품 리스트\n",
    "        k : 상위 몇개의 데이터를 볼지 (ex : k=5 상위 5개의 상품만 봄)\n",
    "    Returns: \n",
    "        recall_k : recall@k \n",
    "    \"\"\" \n",
    "    set_actual = set(actual)\n",
    "    recall_k = len(set_actual & set(predicted[:k])) / min(k, len(set_actual))\n",
    "    return recall_k\n",
    "\n",
    "def unique(sequence):\n",
    "    # preserves order\n",
    "    seen = set()\n",
    "    return [x for x in sequence if not (x in seen or seen.add(x))]\n",
    "\n",
    "def ndcgk(actual, predicted, k = 25):\n",
    "    set_actual = set(actual)\n",
    "    idcg = sum([1.0 / np.log(i + 2) for i in range(min(k, len(set_actual)))])\n",
    "    dcg = 0.0\n",
    "    unique_predicted = unique(predicted[:k])\n",
    "    for i, r in enumerate(unique_predicted):\n",
    "        if r in set_actual:\n",
    "            dcg += 1.0 / np.log(i + 2)\n",
    "    ndcg_k = dcg / idcg\n",
    "    return ndcg_k\n",
    "\n",
    "def evaluation(gt, pred):\n",
    "    \"\"\" label과 prediction 사이의 recall, coverage, competition metric 평가 함수 \n",
    "    Args:\n",
    "        gt : 데이터 프레임 형태의 정답 데이터 \n",
    "        pred : 데이터 프레임 형태의 예측 데이터 \n",
    "    Returns: \n",
    "        rets : recall, ndcg, coverage, competition metric 결과 \n",
    "            ex) {'recall': 0.123024, 'ndcg': 056809, 'coverage': 0.017455, 'score': 0.106470}\n",
    "    \"\"\"    \n",
    "    gt = gt.groupby('uid')['sid'].unique().to_frame().reset_index()\n",
    "    gt.columns = ['uid', 'actual_list']\n",
    "\n",
    "    evaluated_data = pd.merge(pred, gt, how = 'left', on = 'uid')\n",
    "\n",
    "    evaluated_data['Recall@25'] = evaluated_data.apply(lambda x: recallk(x.actual_list, x.predicted_list), axis=1)\n",
    "    evaluated_data['NDCG@25'] = evaluated_data.apply(lambda x: ndcgk(x.actual_list, x.predicted_list), axis=1)\n",
    "\n",
    "    recall = evaluated_data['Recall@25'].mean()\n",
    "    ndcg = evaluated_data['NDCG@25'] .mean()\n",
    "    # coverage = (evaluated_data['predicted_list'].apply(lambda x: x[:cfg.top_k]).explode().nunique())/meta_df.index.nunique()\n",
    "\n",
    "    score = 0.75*recall + 0.25*ndcg\n",
    "    rets = {\"recall\" :recall, \n",
    "            \"ndcg\" :ndcg, \n",
    "            # \"coverage\" :coverage, \n",
    "            \"score\" :score}\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 256])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1 = nn.Embedding(25000, 256)\n",
    "embedding2 = nn.Embedding(3000, 256)\n",
    "a = torch.LongTensor([1] * 6000)\n",
    "embedding1.weight.shape\n",
    "embedding2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 256])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(embedding1(a), embedding1(a)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(cfg, model, data, mode='valid'):\n",
    "    pred_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    query_user_ids = data['uid'].unique() # 추론할 모든 user array 집합\n",
    "    full_item_ids = np.array([c for c in range(cfg.valid_items)]) # 추론할 모든 item array 집합 \n",
    "    full_item_ids_feat1 = [item_features['genre'][c] for c in full_item_ids]\n",
    "    \n",
    "    for user_id in query_user_ids:\n",
    "        with torch.no_grad():\n",
    "            user_ids = np.full(cfg.valid_items, user_id)\n",
    "            \n",
    "            user_ids = torch.LongTensor(user_ids).to(cfg.device)\n",
    "            item_ids = torch.LongTensor(full_item_ids).to(cfg.device)\n",
    "            # feat0 = np.full(cfg.n_items, user_features['age'][user_id])\n",
    "            # feat0 = torch.FloatTensor(feat0).to(cfg.device)\n",
    "            feat1 = torch.LongTensor(full_item_ids_feat1).to(cfg.device)\n",
    "            # print(feat1.shape)\n",
    "            \n",
    "            eval_output = model.forward(user_ids, item_ids, [feat1]).detach().cpu().numpy() # feat0,\n",
    "            pred_u_score = eval_output.reshape(-1)   \n",
    "        \n",
    "        pred_u_idx = np.argsort(pred_u_score)[::-1]\n",
    "        pred_u = full_item_ids[pred_u_idx]\n",
    "        pred_list.append(list(pred_u[:cfg.top_k]))\n",
    "        \n",
    "    pred = pd.DataFrame()\n",
    "    pred['uid'] = query_user_ids\n",
    "    pred['predicted_list'] = pred_list\n",
    "    \n",
    "    # 모델 성능 확인 \n",
    "    if mode == 'valid':\n",
    "        rets = evaluation(data, pred)\n",
    "        return rets, pred\n",
    "    return pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정 \n",
    "cfg.batch_size = 256\n",
    "cfg.emb_dim = 256\n",
    "cfg.layer_dim = 256\n",
    "cfg.dropout = 0.05\n",
    "cfg.epochs = 25\n",
    "cfg.learning_rate = 0.0025\n",
    "cfg.reg_lambda = 0\n",
    "cfg.check_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bottleneck as bn\n",
    "import numpy as np\n",
    "a = [1,2,3,-1, 5,-np.inf,-np.inf,-np.inf]\n",
    "b = [-1,-2,-3,1,-5,np.inf,np.inf,np.inf]\n",
    "np.argsort(a)[-10:]\n",
    "bn.argpartition(a, 5)\n",
    "np.argsort(b)[-10:]\n",
    "bn.argpartition(b, 3)\n",
    "np.argsort(a)[-3:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1., -inf, -inf, -inf, -inf,   1.,   2.,   3.,   4.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,-np.inf,1,2,3,4,])\n",
    "a[[1,2,3]] = -np.inf\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "A = pd.DataFrame({'a' :['1','1','1','2'] , 'b' :['4', '5','6', '8']})\n",
    "idx = A.loc[A['a'] == '1',:]['b'].astype(int)\n",
    "a[idx] = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  = []\n",
    "b = np.array([[1,2,3], [2,3,4]])\n",
    "a.append(b)\n",
    "a = np.concatenate(a)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[39m=\u001b[39m[[\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m]]\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m np\u001b[39m.\u001b[39marray(a)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "a =[[1,2,3]].cpu().numpy()\n",
    "np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 생성 및 optimizer, loss 함수 설정 \n",
    "model = NeuMF(cfg).to(cfg.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate, weight_decay=cfg.reg_lambda)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_logs = defaultdict(list)\n",
    "best_scores  = 0\n",
    "for epoch in range(cfg.epochs+1):\n",
    "    cfg.epoch = epoch\n",
    "    train_results = train_epoch(cfg, model, optimizer, criterion)\n",
    "    \n",
    "    # cfg.check_epoch 번의 epoch 마다 성능 확인 \n",
    "    if epoch % cfg.check_epoch == 0: \n",
    "        valid_results, _ = valid_epoch(cfg, model, vad_data)\n",
    "\n",
    "        logs = {\n",
    "            'Train Loss': train_results['losses'],\n",
    "            f'Valid Recall@{cfg.top_k}': valid_results['recall'],\n",
    "            f'Valid NDCG@{cfg.top_k}': valid_results['ndcg'],\n",
    "            # 'Valid Coverage': valid_results['coverage'],\n",
    "            'Valid Score': valid_results['score'],\n",
    "            }\n",
    "\n",
    "        # 검증 성능 확인 \n",
    "        for key, value in logs.items():\n",
    "            total_logs[key].append(value)\n",
    "\n",
    "        if epoch == 0:\n",
    "            print(\"Epoch\", end=\",\")\n",
    "            print(\",\".join(logs.keys()))\n",
    "\n",
    "        print(f\"{epoch:02d}  \", end=\"\")\n",
    "        print(\"  \".join([f\"{v:0.6f}\" for v in logs.values()]))\n",
    "        \n",
    "        가장 성능이 좋은 가중치 파일을 저장 \n",
    "        if best_scores <= valid_results['score']: \n",
    "            best_scores = valid_results['score']\n",
    "            torch.save(model.state_dict(), os.path.join(saved_path, 'model(best_scores).pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
