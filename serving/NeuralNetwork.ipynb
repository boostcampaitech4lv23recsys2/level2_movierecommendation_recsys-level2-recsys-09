{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import implicit\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split as data_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_items:int=6807, bn_dim:int=100,p:float=0.5):\n",
    "        super().__init__()\n",
    "        self.item_encoder = LabelEncoder()\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        dims = [n_items, bn_dim, n_items]\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(dims[i],dims[i+1]) for i in range(len(dims)-1)]\n",
    "        )\n",
    "        # self.linear = nn.Linear(n_items, bn_dim)\n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.n_items = n_items\n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame):\n",
    "        ucol, icol = df.columns\n",
    "        items = self.item_encoder.fit_transform(df.loc[:,icol])\n",
    "        users = self.user_encoder.fit_transform(df.loc[:,ucol])\n",
    "        return users, items\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        # with torch.no_grad():\n",
    "        #     self.linear.weight.fill_diagonal_(0.)\n",
    "        x = self.drop(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        # x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def item_ids2tensor(self, input_ids:list) -> torch.Tensor:\n",
    "        input_tensor = np.zeros((1, self.n_items), dtype=float)\n",
    "        items = self.item_encoder.transform(input_ids)\n",
    "        input_tensor[0,items] = 1.\n",
    "        input_tensor = torch.FloatTensor(input_tensor).to(device)\n",
    "        return input_tensor\n",
    "\n",
    "    def predict_k(self, input_ids:list, k:int=10) -> pd.DataFrame:\n",
    "        input_tensor = self.item_ids2tensor(input_ids)\n",
    "        predictions = self.forward(input_tensor)[0].detach().cpu().numpy() # [[predictions]]\n",
    "        predictions[self.item_encoder.transform(input_ids)] = -np.inf\n",
    "        result_id = np.argpartition(predictions, -k)[-k:]\n",
    "        sorted_order = np.argsort(-predictions[result_id])\n",
    "        result_id = result_id[sorted_order]\n",
    "        result_pred = predictions[result_id]\n",
    "        return self.item_encoder.inverse_transform(result_id), result_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_validation(matrix:sparse.csr_matrix, n:int=10, n_item:int=6807):\n",
    "    input_rows = []\n",
    "    input_cols = []\n",
    "    target_rows = []\n",
    "    target_cols = []\n",
    "    n_rows = matrix.shape[0]\n",
    "    for i, item_seq in tqdm(enumerate(matrix.toarray()),total=n_rows):\n",
    "        items = np.where(item_seq == 1)[0]\n",
    "        target_idx = np.random.choice(len(items),size=(n),replace=False)\n",
    "        # 레이블 저장\n",
    "        target_items = items[target_idx]\n",
    "        target_rows.append([i]*n)\n",
    "        target_cols.append(target_items)\n",
    "        \n",
    "        # 입력 데이터 마스킹으로 저장\n",
    "        mask = np.ones(len(items), dtype=bool)\n",
    "        mask[target_idx] = False\n",
    "        input_items = items[mask]\n",
    "\n",
    "        input_rows.append([i]*len(input_items))\n",
    "        input_cols.append(input_items)\n",
    "    input_rows = np.concatenate(input_rows)\n",
    "    input_cols = np.concatenate(input_cols)\n",
    "    input_vals = np.ones(len(input_rows))\n",
    "    target_rows = np.concatenate(target_rows)\n",
    "    target_cols = np.concatenate(target_cols)\n",
    "    target_vals = np.ones(len(target_rows))\n",
    "\n",
    "    return sparse.csr_matrix((input_vals,(input_rows,input_cols)),shape=(n_rows,n_item)),sparse.csr_matrix((target_vals,(target_rows,target_cols)),shape=(n_rows,n_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    Normalized Discounted Cumulative Gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = np.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG\n",
    "\n",
    "\n",
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = np.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sparse2tensor(data):\n",
    "    return torch.FloatTensor(data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/train/train_ratings.csv')\n",
    "df = df[['user','item']]\n",
    "model = NeuralNetwork()\n",
    "ui, ii = model.preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3136/3136 [00:00<00:00, 19736.83it/s]\n",
      "100%|██████████| 3136/3136 [00:00<00:00, 19622.62it/s]\n"
     ]
    }
   ],
   "source": [
    "values = (np.ones(len(ui)))\n",
    "full_matrix = sparse.csr_matrix((values,(ui,ii)))\n",
    "# Split into train and valid set\n",
    "train_matrix, test_full = data_split(full_matrix, train_size=0.8)\n",
    "valid_matrix, test_matrix = data_split(test_full, train_size=0.5)\n",
    "# Split to valid and test set\n",
    "valid_input, valid_target = split_validation(valid_matrix)\n",
    "test_input, test_target = split_validation(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import F\n",
    "def loss_function_dae(recon_x, x):\n",
    "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    return BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "epochs = 20\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = loss_function_dae\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "log_interval = 100\n",
    "save = './weights/model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, train_data):\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    n_rows = train_data.shape[0]\n",
    "    idx_list = list(range(train_data.shape[0]))\n",
    "    start_time = time.time()\n",
    "\n",
    "    np.random.shuffle(idx_list)\n",
    "    \n",
    "    for batch_idx, start_idx in enumerate(range(0, n_rows, batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, n_rows)\n",
    "        data = train_data[idx_list[start_idx:end_idx]]\n",
    "        data = naive_sparse2tensor(data).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_batch = model(data)\n",
    "        loss = criterion(recon_batch, data)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if batch_idx % log_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
    "                    'loss {:4.2f}'.format(\n",
    "                        epoch, batch_idx, len(range(0, n_rows, batch_size)),\n",
    "                        elapsed * 1000 / log_interval,\n",
    "                        train_loss / log_interval))\n",
    "            \n",
    "\n",
    "            start_time = time.time()\n",
    "            train_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, inputs:sparse.csr_matrix,targets:sparse.csr_matrix, k:int=10):\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    total_loss = 0.0\n",
    "    n_rows = inputs.shape[0]\n",
    "    idx_list = list(range(inputs.shape[0]))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, n_rows, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, n_rows)\n",
    "            data = inputs[idx_list[start_idx:end_idx]]\n",
    "            heldout_data = targets[idx_list[start_idx:end_idx]]\n",
    "\n",
    "            data_tensor = naive_sparse2tensor(data).to(device)\n",
    "            recon_batch = model(data_tensor)\n",
    "\n",
    "            loss = criterion(recon_batch, data_tensor)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Exclude examples from training set\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            recon_batch[data.nonzero()] = -np.inf\n",
    "\n",
    "            n10 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 10)\n",
    "            r10 = Recall_at_k_batch(recon_batch, heldout_data, 10)\n",
    "\n",
    "            ndcgs.append(n10)\n",
    "            recalls.append(r10)\n",
    "\n",
    "    total_loss /= len(range(0, n_rows, batch_size))\n",
    "    recalls = np.concatenate(recalls)\n",
    "    ndcgs = np.concatenate(ndcgs)\n",
    "    return total_loss, np.mean(recalls), np.mean(ndcgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, train_matrix, valid_input, valid_target, test_input, test_target):\n",
    "    n_rows = train_matrix.shape[0]\n",
    "    idxlist = list(range(n_rows))\n",
    "\n",
    "    best_r10 = -np.inf\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model, epoch, train_matrix)\n",
    "        val_loss, r10, n10= evaluate(model, valid_input, valid_target)\n",
    "        print('-' * 102)\n",
    "        print('| end of epoch {:3d} | time: {:4.4f}s | valid loss {:4.4f} | '\n",
    "                'n10 {:5.4f} | r10 {:5.4f} |'.format(\n",
    "                    epoch, time.time() - epoch_start_time, val_loss,\n",
    "                    n10, r10))\n",
    "        print('-' * 102)\n",
    "\n",
    "        n_iter = epoch * len(range(0, n_rows, batch_size))\n",
    "\n",
    "\n",
    "        # Save the self.model if the r10 is the best we've seen so far.\n",
    "        if r10 > best_r10:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_r10 = r10\n",
    "\n",
    "\n",
    "    # Load the best saved self.model.\n",
    "    with open(save, 'rb') as f:\n",
    "        model = torch.load(f)\n",
    "\n",
    "    # Run on test data.\n",
    "    test_loss, r10, n10 = evaluate(model, test_input, test_target)\n",
    "    print('=' * 102)\n",
    "    print('| End of training | test loss {:4.4f} | n10 {:4.4f} | r10 {:4.4f} |'.format(test_loss, n10, r10))\n",
    "    print('=' * 102)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 1.3794s | valid loss 0.0178 | n10 0.0961 | r10 0.0857 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 1.4822s | valid loss 0.0163 | n10 0.1378 | r10 0.1203 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 1.4164s | valid loss 0.0156 | n10 0.1582 | r10 0.1365 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 1.4284s | valid loss 0.0153 | n10 0.1685 | r10 0.1447 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 1.4275s | valid loss 0.0150 | n10 0.1756 | r10 0.1507 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 1.5073s | valid loss 0.0149 | n10 0.1823 | r10 0.1563 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 1.4785s | valid loss 0.0147 | n10 0.1890 | r10 0.1621 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 1.4810s | valid loss 0.0145 | n10 0.1935 | r10 0.1652 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 1.5623s | valid loss 0.0144 | n10 0.1970 | r10 0.1689 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 1.4306s | valid loss 0.0143 | n10 0.2002 | r10 0.1706 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 1.3893s | valid loss 0.0142 | n10 0.2040 | r10 0.1741 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 1.4175s | valid loss 0.0141 | n10 0.2066 | r10 0.1755 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 1.5590s | valid loss 0.0141 | n10 0.2092 | r10 0.1775 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 1.5263s | valid loss 0.0140 | n10 0.2088 | r10 0.1767 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 1.4795s | valid loss 0.0139 | n10 0.2118 | r10 0.1794 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 1.4020s | valid loss 0.0139 | n10 0.2131 | r10 0.1802 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 1.4981s | valid loss 0.0138 | n10 0.2155 | r10 0.1828 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 1.5425s | valid loss 0.0138 | n10 0.2159 | r10 0.1827 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 1.4960s | valid loss 0.0138 | n10 0.2170 | r10 0.1839 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 1.5106s | valid loss 0.0137 | n10 0.2167 | r10 0.1837 |\n",
      "------------------------------------------------------------------------------------------------------\n",
      "======================================================================================================\n",
      "| End of training | test loss 0.0146 | n10 0.2205 | r10 0.1844 |\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "run(model, train_matrix, valid_input, valid_target, test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./weights/model.pt', 'rb') as f:\n",
    "    model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154471 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item\n",
       "0            11   4643\n",
       "1            11    170\n",
       "2            11    531\n",
       "3            11    616\n",
       "4            11   2140\n",
       "...         ...    ...\n",
       "5154466  138493  44022\n",
       "5154467  138493   4958\n",
       "5154468  138493  68319\n",
       "5154469  138493  40819\n",
       "5154470  138493  27311\n",
       "\n",
       "[5154471 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2571,   318,  2959,   356,   296, 58559,   593,  2858,  4993,\n",
       "         7153]),\n",
       " array([0.21931747, 0.19804136, 0.19775712, 0.18754138, 0.18538935,\n",
       "        0.14561966, 0.14055654, 0.13715774, 0.12422715, 0.11471848],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_k([4643])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('item_classes.txt',model.item_encoder.classes_,fmt=\"%d\")\n",
    "np.savetxt('user_classes.txt',model.user_encoder.classes_,fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt('item_classes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder().fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      2,      3, ..., 118997, 119141, 119145])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./weights/state.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
